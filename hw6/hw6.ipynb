{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae151b84",
   "metadata": {},
   "source": [
    "# Рекомендательные системы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d128929d",
   "metadata": {},
   "source": [
    "## Урок 6. Двухуровневые модели рекомендаций"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8e6d70",
   "metadata": {},
   "source": [
    "**Примечание**. Это заготовка к практической работе №6. Планирую добавить материал в течение нескольких дней."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c03cc13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import bsr_matrix\n",
    "\n",
    "from implicit.als import AlternatingLeastSquares\n",
    "from implicit.nearest_neighbours import ItemItemRecommender\n",
    "\n",
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54eceba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "RETAIL_DATA = \"../hw2/retail_train.csv.zip\"\n",
    "PRODUCT_DATA = \"../hw2/product.csv\"\n",
    "DEMOGRAPHIC_DATA = \"../hw5/hh_demographic.csv\"\n",
    "VAL_MATCHER_WEEKS = 6\n",
    "VAL_RANKER_WEEKS = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69b551fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ITEM_ID_COL = 'item_id'\n",
    "USER_ID_COL = 'user_id'\n",
    "ITEM_INDEX_COL = 'item_idx'\n",
    "USER_INDEX_COL = 'user_idx'\n",
    "WEEK_NUM_COL = 'week_no'\n",
    "ACTUAL_COL = 'actual'\n",
    "TOPK_PRECISION = 5\n",
    "TOPK_RECALL = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e23f68c8",
   "metadata": {},
   "source": [
    "### Библиотека"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "048bbc89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precision@K\n",
    "def precision_at_k(recommended_list, bought_list, k=5):\n",
    "    try:\n",
    "        _rec_list = recommended_list[:k]\n",
    "        _b_and_r = np.intersect1d(bought_list, _rec_list)\n",
    "        return _b_and_r.size / len(_rec_list)\n",
    "    except (ZeroDivisionError, TypeError):\n",
    "        return 0.0\n",
    "\n",
    "def mean_precision_at_k(df, rec, bought, k=5):\n",
    "    _result = df.apply(\n",
    "        lambda row: precision_at_k(row[rec], row[bought], k),\n",
    "        axis=1\n",
    "    )\n",
    "    return np.mean(_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a60f8442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recall@K\n",
    "def recall_at_k(recommended_list, bought_list, k=5):\n",
    "    try:\n",
    "        _rec_list = recommended_list[:k]\n",
    "        _b_and_r = np.intersect1d(bought_list, _rec_list)\n",
    "        return _b_and_r.size / len(bought_list)\n",
    "    except (ZeroDivisionError, TypeError):\n",
    "        return 0.0\n",
    "\n",
    "def mean_recall_at_k(df, rec, bought, k=5):\n",
    "    _result = df.apply(\n",
    "        lambda row: recall_at_k(row[rec], row[bought], k),\n",
    "        axis=1\n",
    "    )\n",
    "    return np.mean(_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "956c2f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_transform_csv(path, column_map={}, index=None):\n",
    "    columns = pd.read_csv(path, nrows=0).columns\n",
    "    _column_map = dict(zip(columns, columns.str.lower()))\n",
    "    _column_map.update(column_map)\n",
    "    _data = pd.read_csv(path).rename(columns=_column_map)\n",
    "    if index is not None:\n",
    "        return _data.set_index(index)    \n",
    "    return _data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7b3a9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Предфильтрация\n",
    "def prefilter_items(data, prevalence_range = (0.05, 0.95), price_range = (1.0, 100.0)):\n",
    "    # Уберем самые популярные товары и самые непопулярные товары\n",
    "    pop_thr, unpop_thr = prevalence_range\n",
    "    item_cum_counts = data[ITEM_ID_COL].value_counts().cumsum()\n",
    "    max_count = item_cum_counts.values[-1]\n",
    "    top_popular_mask = item_cum_counts < max_count * pop_thr\n",
    "    top_uppopular_mask = item_cum_counts > max_count * unpop_thr\n",
    "    blocked_items = item_cum_counts[top_popular_mask | top_uppopular_mask].index\n",
    "    \n",
    "    # Уберем товары, которые не продавались за последние 12 месяцев\n",
    "    recent_sale_items = data[ITEM_ID_COL][data[WEEK_NUM_COL] > data[WEEK_NUM_COL].max() - 53]\n",
    "    old_sale_items = np.setdiff1d(data[ITEM_ID_COL], recent_sale_items)\n",
    "    blocked_items = np.union1d(blocked_items, old_sale_items)\n",
    "    \n",
    "    # Уберем слишком дешевые товары и слишком дорогие товары\n",
    "    # Цена товара косвенно оценивается по sales_value\n",
    "    min_price, max_price = price_range\n",
    "    bad_price_items = (\n",
    "        data\n",
    "        .assign(price = lambda x: np.where(x['quantity'] > 0, x['sales_value'] / x['quantity'], 0.0))\n",
    "        .groupby(ITEM_ID_COL)\n",
    "        .agg(min_item_price=('price', 'min'), max_item_price=('price', 'max'))\n",
    "        .query(\"min_item_price >= @max_price or max_item_price <= @min_price\")\n",
    "        .index\n",
    "    )\n",
    "    blocked_items = np.union1d(blocked_items, bad_price_items)\n",
    "    return data[~np.isin(data[ITEM_ID_COL], blocked_items)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dbe4c7c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RecResult - класс, аккумулирующий результаты работы разных рекомендательных моделей\n",
    "class RecResult:\n",
    "    def __init__(self, data_train, aggcol, aggfunc):\n",
    "        agg_df = (\n",
    "            data_train.groupby([USER_ID_COL, ITEM_ID_COL])\n",
    "            .agg(interaction=(aggcol, aggfunc))\n",
    "            .reset_index()\n",
    "        )\n",
    "        self.user_idx_id = pd.DataFrame(enumerate(np.sort(agg_df[USER_ID_COL].unique())), \n",
    "                                        columns=[USER_INDEX_COL, USER_ID_COL])\n",
    "        self.item_idx_id = pd.DataFrame(enumerate(np.sort(agg_df[ITEM_ID_COL].unique())), \n",
    "                                        columns=[ITEM_INDEX_COL, ITEM_ID_COL])\n",
    "        self.user_item_interaction = (\n",
    "            agg_df\n",
    "            .merge(self.user_idx_id, on=USER_ID_COL)\n",
    "            .merge(self.item_idx_id, on=ITEM_ID_COL)\n",
    "        )\n",
    "        interaction = self.user_item_interaction['interaction'].astype(float)\n",
    "        user_idx = self.user_item_interaction[USER_INDEX_COL]\n",
    "        item_idx = self.user_item_interaction[ITEM_INDEX_COL]\n",
    "        self.user_item_matrix = bsr_matrix((interaction, (user_idx, item_idx)), \n",
    "                                           shape=(user_idx.max()+1, item_idx.max()+1)).tocsr()\n",
    "        \n",
    "    def init_result(self, data_test):  # init result with actuals\n",
    "        self.actual = data_test.groupby(USER_ID_COL).agg(actual=(ITEM_ID_COL, list))\n",
    "        self.result = (\n",
    "            self.actual\n",
    "            .merge(self.user_idx_id, on=USER_ID_COL, how='inner')\n",
    "            .filter([USER_ID_COL, USER_INDEX_COL, ACTUAL_COL])        \n",
    "        )\n",
    "        return self\n",
    "    \n",
    "    def _get_recommendations(self, model, userid, N):\n",
    "        rec = model.recommend(userid, self.user_item_matrix.tocsr(), N=N,\n",
    "                              filter_already_liked_items=False,\n",
    "                              recalculate_user=False)\n",
    "        rec_df = pd.DataFrame(rec, columns=[ITEM_INDEX_COL, 'model_score']).set_index(ITEM_INDEX_COL)\n",
    "        return rec_df.join(self.item_idx_id)[ITEM_ID_COL].tolist()\n",
    "        \n",
    "    \n",
    "    def add_all_recommendations(self, model, N=5, model_name=None, show_progress=False):\n",
    "        if model_name is None:\n",
    "            model_name = model.__class__.__name__\n",
    "        \n",
    "        model.fit(self.user_item_matrix.T, show_progress=show_progress)\n",
    "        if hasattr(model, 'user_factors') and hasattr(model, 'item_factors'):\n",
    "            fast_recs = model.user_factors @ model.item_factors.T\n",
    "            item_ids = self.item_idx_id[ITEM_ID_COL].values\n",
    "            rec_matrix = item_ids[np.argsort(-fast_recs)[:, :N]]\n",
    "            rec_df = pd.DataFrame.from_records(\n",
    "                np.expand_dims(rec_matrix, axis=1),\n",
    "                columns = [model_name],\n",
    "                index=self.user_idx_id[USER_INDEX_COL]\n",
    "            )\n",
    "            self.result = self.result.join(rec_df)\n",
    "        else:        \n",
    "            def _get_user_rec(userid):\n",
    "                return self._get_recommendations(model=model, userid=userid, N=N) \n",
    "        \n",
    "            self.result[model_name] = self.result[USER_INDEX_COL].apply(_get_user_rec)        \n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c193fd92",
   "metadata": {},
   "source": [
    "### Данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d31f2499",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decreased # of items from 83685 to 5426\n",
      "Wall time: 4.91 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "item_features = read_transform_csv(PRODUCT_DATA, {'PRODUCT_ID': ITEM_ID_COL}, index=ITEM_ID_COL)\n",
    "user_features = read_transform_csv(DEMOGRAPHIC_DATA, {'household_key': USER_ID_COL}, index=USER_ID_COL)\n",
    "\n",
    "# train test split\n",
    "data = pd.read_csv(RETAIL_DATA)\n",
    "# берем данные для тренировки matching модели\n",
    "data_train_matcher = data[data[WEEK_NUM_COL] < data[WEEK_NUM_COL].max() - (VAL_MATCHER_WEEKS + VAL_RANKER_WEEKS)]\n",
    "# берем данные для валидации matching модели\n",
    "data_val_matcher = data[(data[WEEK_NUM_COL] >= data[WEEK_NUM_COL].max() - (VAL_MATCHER_WEEKS + VAL_RANKER_WEEKS)) &\n",
    "                      (data[WEEK_NUM_COL] < data[WEEK_NUM_COL].max() - (VAL_RANKER_WEEKS))]\n",
    "# берем данные для тренировки ranking модели\n",
    "data_train_ranker = data_val_matcher.copy()  # Для наглядности. Далее мы добавим изменения, и они будут отличаться\n",
    "# берем данные для теста ranking, matching модели\n",
    "data_val_ranker = data[data[WEEK_NUM_COL] >= data[WEEK_NUM_COL].max() - VAL_RANKER_WEEKS]\n",
    "\n",
    "# Prefiltered\n",
    "data_train_matcher_filtered = prefilter_items(data_train_matcher, prevalence_range = (0.05, 0.75), price_range = (1.8, 50.0))\n",
    "print(f\"Decreased # of items from {data_train_matcher[ITEM_ID_COL].nunique()}\"\n",
    "      f\" to {data_train_matcher_filtered[ITEM_ID_COL].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16cc3744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Result Accumulator\n",
    "recresult = RecResult(data_train_matcher_filtered, 'quantity', 'count').init_result(data_val_matcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "553a69e7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 32.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "own_recommender = ItemItemRecommender(K=1, num_threads=4)\n",
    "als_recommender = AlternatingLeastSquares(factors=3, regularization=0.05, iterations=10)\n",
    "\n",
    "recall_results = []\n",
    "\n",
    "for k in (20, 50, 100, 200, 500):\n",
    "    model_name=f\"Own Rec, N={k}\"\n",
    "    recresult.add_all_recommendations(own_recommender, N=k, model_name=model_name)\n",
    "    recall_results.append((model_name, mean_recall_at_k(recresult.result, model_name, 'actual', k=k)))\n",
    "    model_name=f\"ALS, N={k}\"\n",
    "    recresult.add_all_recommendations(als_recommender, N=k, model_name=model_name)\n",
    "    recall_results.append((model_name, mean_recall_at_k(recresult.result, model_name, 'actual', k=k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84288396",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ALS, N=500</td>\n",
       "      <td>0.126230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>ALS, N=200</td>\n",
       "      <td>0.082332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Own Rec, N=500</td>\n",
       "      <td>0.078483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Own Rec, N=200</td>\n",
       "      <td>0.078476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Own Rec, N=100</td>\n",
       "      <td>0.077368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Own Rec, N=50</td>\n",
       "      <td>0.068262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ALS, N=100</td>\n",
       "      <td>0.056417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Own Rec, N=20</td>\n",
       "      <td>0.046991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ALS, N=50</td>\n",
       "      <td>0.038030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALS, N=20</td>\n",
       "      <td>0.019701</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model    Recall\n",
       "9      ALS, N=500  0.126230\n",
       "7      ALS, N=200  0.082332\n",
       "8  Own Rec, N=500  0.078483\n",
       "6  Own Rec, N=200  0.078476\n",
       "4  Own Rec, N=100  0.077368\n",
       "2   Own Rec, N=50  0.068262\n",
       "5      ALS, N=100  0.056417\n",
       "0   Own Rec, N=20  0.046991\n",
       "3       ALS, N=50  0.038030\n",
       "1       ALS, N=20  0.019701"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(recall_results, columns=['Model', 'Recall']).sort_values('Recall', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69bef60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
